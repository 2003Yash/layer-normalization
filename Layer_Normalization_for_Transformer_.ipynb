{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaKqamyVAOqB3m+p+OGfr9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003Yash/layer-normalization/blob/main/Layer_Normalization_for_Transformer_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get a word embedding vector from multi-head attention block and each head will give a vector now we will add the all attention head vector intoa single vector and we also has a residual connection from the original word embedding ( so that we don't vary much from the original word or the original context ) and we perform this normalization so that the learnable prams in neural will not flutuate too much in the back propagation updation phase\n"
      ],
      "metadata": {
        "id": "iLyOImHGzA_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first we get a matrix which is added version of attention vectors from all the attention heads and we find mean and s.d for all rows and then we use  ->  formula (x-mean)/s.d for all values in matrix\n",
        "-> then norm formula = alpha*Y + b (Here alpha and beta are learnable params and alpha is multiplied withh all y values ) the matrix resultant after this process is normalized matrix"
      ],
      "metadata": {
        "id": "RUCKQ4O1I_fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class LayerNormalization(tf.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        self.parameters_shape = parameters_shape\n",
        "        self.eps = eps\n",
        "        self.gamma = tf.Variable(tf.ones(parameters_shape), trainable=True)\n",
        "        self.beta = tf.Variable(tf.zeros(parameters_shape), trainable=True)\n",
        "\n",
        "# The whole process is explained in the 2nd text cell in this file\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        dims = [-i for i in range(1, len(self.parameters_shape) + 1)]\n",
        "        mean = tf.reduce_mean(inputs, axis=dims, keepdims=True)\n",
        "        print(f\"Mean \\n ({mean.shape}): \\n {mean}\")\n",
        "        var = tf.reduce_mean(tf.square(inputs - mean), axis=dims, keepdims=True)\n",
        "        std = tf.sqrt(var + self.eps)\n",
        "        print(f\"Standard Deviation \\n ({std.shape}): \\n {std}\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y \\n ({y.shape}) = \\n {y}\")\n",
        "        out = self.gamma * y + self.beta\n",
        "        print(f\"out \\n ({out.shape}) = \\n {out}\")\n",
        "        return out"
      ],
      "metadata": {
        "id": "_z0o7CnG1ewG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8\n",
        "inputs = tf.random.normal(shape=(sentence_length, batch_size, embedding_dim))"
      ],
      "metadata": {
        "id": "MBFzEjLK4C1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"input \\n ({inputs.shape}) = \\n {inputs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wC2KAzY4FUT",
        "outputId": "c87c3016-0820-47c2-d9b6-fbc5478be843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input \n",
            " ((5, 3, 8)) = \n",
            " [[[-1.0038837e+00 -9.5244807e-01 -1.6853817e+00 -2.7049094e-01\n",
            "    1.3179457e-01 -1.9687043e+00 -1.9520327e-01  2.4850056e-01]\n",
            "  [-1.5948204e+00  6.2333506e-01  9.7797382e-01  2.9508597e-01\n",
            "    1.1022136e+00 -5.3846568e-01  1.9445401e-01 -7.3187083e-01]\n",
            "  [ 7.6458985e-01 -1.5157856e-01 -2.5566173e+00  1.1122432e-01\n",
            "    8.3853531e-01  1.3742457e-01  6.1803114e-01 -4.6780297e-01]]\n",
            "\n",
            " [[-5.3838140e-01  3.8508824e-01  1.0166631e+00  2.0144999e+00\n",
            "   -8.0260873e-01  6.2671983e-01 -9.8531656e-02 -4.7026455e-01]\n",
            "  [-3.0046874e-01 -1.3527232e-02  1.2161305e+00 -4.0085322e-01\n",
            "   -1.3490324e+00  6.7868131e-01  1.3866105e+00 -6.8107778e-01]\n",
            "  [ 7.2391754e-01  4.8476183e-01 -5.9137559e-01  1.2990150e+00\n",
            "   -2.6015815e-01 -3.3298323e-01  5.9793252e-01  1.4928647e+00]]\n",
            "\n",
            " [[ 6.3440102e-01  4.4141170e-01  3.0047151e-01 -2.7355605e-01\n",
            "   -1.1412312e+00  6.9188708e-01 -9.7919688e-02  2.8614568e-02]\n",
            "  [ 1.3173200e+00 -4.3998680e-01 -3.8386998e-01 -1.4733223e+00\n",
            "   -1.8362412e+00 -1.0826464e+00 -4.2380637e-01 -2.2430429e+00]\n",
            "  [-1.1236924e+00  2.0739975e+00  1.2292436e+00  9.0361824e-03\n",
            "   -9.8397052e-01 -5.3902078e-01  8.1513685e-01 -8.4714919e-01]]\n",
            "\n",
            " [[-1.9262600e+00 -9.2606151e-01  1.0430919e+00 -3.5455975e-01\n",
            "   -1.0127821e+00 -1.1429039e+00 -2.7921328e-01 -2.1228092e+00]\n",
            "  [ 1.7411683e+00 -1.1709760e+00 -2.6610577e-01 -6.7673498e-01\n",
            "    8.9270854e-01  2.9713237e-01  1.6784360e-01  4.1612560e-01]\n",
            "  [-3.6136743e-01 -2.0714115e-01 -4.7700542e-01 -5.3698981e-01\n",
            "   -2.5328095e+00  9.3481923e-04 -1.1062555e+00  1.3472389e+00]]\n",
            "\n",
            " [[-3.4093454e-01  8.7957525e-01  2.5532830e-01 -4.3745717e-01\n",
            "   -1.1046573e-01  6.7216790e-01 -4.0639403e-01  1.7085712e-01]\n",
            "  [-5.6182104e-01  2.5845084e-01 -7.1195841e-01  2.2581446e-01\n",
            "    7.5506407e-01  6.0828030e-01  5.3115147e-01  1.0679275e+00]\n",
            "  [ 7.4031675e-01 -1.8200605e-01  5.5075234e-01 -9.7869866e-02\n",
            "   -7.2195955e-02 -1.9015764e-01 -2.2976460e-01  4.5222020e-01]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_norm = LayerNormalization(inputs.shape[-1:])"
      ],
      "metadata": {
        "id": "NqUN3gNE4HIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = layer_norm(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASj82nF-4Iz8",
        "outputId": "74a4344f-2342-437f-bea1-96c047ad4c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean \n",
            " ((5, 3, 1)): \n",
            " [[[-0.7119771 ]\n",
            "  [ 0.04098821]\n",
            "  [-0.08827421]]\n",
            "\n",
            " [[ 0.26664808]\n",
            "  [ 0.06705788]\n",
            "  [ 0.42674685]]\n",
            "\n",
            " [[ 0.07300987]\n",
            "  [-0.8206995 ]\n",
            "  [ 0.07919765]]\n",
            "\n",
            " [[-0.8401872 ]\n",
            "  [ 0.17514521]\n",
            "  [-0.4841744 ]]\n",
            "\n",
            " [[ 0.08533464]\n",
            "  [ 0.27161366]\n",
            "  [ 0.1214119 ]]]\n",
            "Standard Deviation \n",
            " ((5, 3, 1)): \n",
            " [[[0.7718832 ]\n",
            "  [0.86893713]\n",
            "  [1.0257196 ]]\n",
            "\n",
            " [[0.88240063]\n",
            "  [0.89171743]\n",
            "  [0.7162508 ]]\n",
            "\n",
            " [[0.5602884 ]\n",
            "  [1.0376303 ]\n",
            "  [1.0992057 ]]\n",
            "\n",
            " [[0.9388038 ]\n",
            "  [0.84947455]\n",
            "  [1.0166148 ]]\n",
            "\n",
            " [[0.46725726]\n",
            "  [0.58233607]\n",
            "  [0.36655864]]]\n",
            "y \n",
            " ((5, 3, 8)) = \n",
            " [[[-0.37817457 -0.311538   -1.2610775   0.57195985  1.0931339\n",
            "   -1.6281314   0.66949743  1.2443304 ]\n",
            "  [-1.8825396   0.67018294  1.0783123   0.29242364  1.2212913\n",
            "   -0.6668536   0.17661324 -0.88943034]\n",
            "  [ 0.8314787  -0.06171701 -2.40645     0.19449617  0.90357006\n",
            "    0.22003944  0.688595   -0.3700122 ]]\n",
            "\n",
            " [[-0.91231745  0.13422492  0.84997106  1.9807917  -1.2117589\n",
            "    0.40805927 -0.413848   -0.83512247]\n",
            "  [-0.41215593 -0.09037068  1.2886063  -0.5247302  -1.5880482\n",
            "    0.6858937   1.479788   -0.8389829 ]\n",
            "  [ 0.41489756  0.08099815 -1.4214609   1.2178252  -0.95902866\n",
            "   -1.060704    0.23900242  1.4884701 ]]\n",
            "\n",
            " [[ 1.0019681   0.6575217   0.4059724  -0.61854917 -2.1671712\n",
            "    1.104569   -0.30507421 -0.07923652]\n",
            "  [ 2.060483    0.36690593  0.42098764 -0.628955   -0.9787125\n",
            "   -0.2524472   0.38249958 -1.3707613 ]\n",
            "  [-1.0943266   1.8147647   1.0462518  -0.06382924 -0.9672149\n",
            "   -0.5624229   0.66951907 -0.842742  ]]\n",
            "\n",
            " [[-1.1568688  -0.09147206  2.0060413   0.5172832  -0.18384555\n",
            "   -0.32244942  0.59754115 -1.3662301 ]\n",
            "  [ 1.8435198  -1.5846517  -0.5194399  -1.0028319   0.84471434\n",
            "    0.14360309 -0.00859545  0.2836817 ]\n",
            "  [ 0.1207999   0.27250564  0.00705181 -0.05195223 -2.0151536\n",
            "    0.47718096 -0.61191434  1.801482  ]]\n",
            "\n",
            " [[-0.9122794   1.699793    0.3638117  -1.1188521  -0.41904187\n",
            "    1.2559104  -1.0523725   0.1830308 ]\n",
            "  [-1.4311919  -0.02260348 -1.6890111  -0.07864736  0.83019143\n",
            "    0.5781312   0.4456839   1.3674471 ]\n",
            "  [ 1.6884197  -0.82774734  1.1712735  -0.5982174  -0.5281771\n",
            "   -0.84998554 -0.95803636  0.9024703 ]]]\n",
            "out \n",
            " ((5, 3, 8)) = \n",
            " [[[-0.37817457 -0.311538   -1.2610775   0.57195985  1.0931339\n",
            "   -1.6281314   0.66949743  1.2443304 ]\n",
            "  [-1.8825396   0.67018294  1.0783123   0.29242364  1.2212913\n",
            "   -0.6668536   0.17661324 -0.88943034]\n",
            "  [ 0.8314787  -0.06171701 -2.40645     0.19449617  0.90357006\n",
            "    0.22003944  0.688595   -0.3700122 ]]\n",
            "\n",
            " [[-0.91231745  0.13422492  0.84997106  1.9807917  -1.2117589\n",
            "    0.40805927 -0.413848   -0.83512247]\n",
            "  [-0.41215593 -0.09037068  1.2886063  -0.5247302  -1.5880482\n",
            "    0.6858937   1.479788   -0.8389829 ]\n",
            "  [ 0.41489756  0.08099815 -1.4214609   1.2178252  -0.95902866\n",
            "   -1.060704    0.23900242  1.4884701 ]]\n",
            "\n",
            " [[ 1.0019681   0.6575217   0.4059724  -0.61854917 -2.1671712\n",
            "    1.104569   -0.30507421 -0.07923652]\n",
            "  [ 2.060483    0.36690593  0.42098764 -0.628955   -0.9787125\n",
            "   -0.2524472   0.38249958 -1.3707613 ]\n",
            "  [-1.0943266   1.8147647   1.0462518  -0.06382924 -0.9672149\n",
            "   -0.5624229   0.66951907 -0.842742  ]]\n",
            "\n",
            " [[-1.1568688  -0.09147206  2.0060413   0.5172832  -0.18384555\n",
            "   -0.32244942  0.59754115 -1.3662301 ]\n",
            "  [ 1.8435198  -1.5846517  -0.5194399  -1.0028319   0.84471434\n",
            "    0.14360309 -0.00859545  0.2836817 ]\n",
            "  [ 0.1207999   0.27250564  0.00705181 -0.05195223 -2.0151536\n",
            "    0.47718096 -0.61191434  1.801482  ]]\n",
            "\n",
            " [[-0.9122794   1.699793    0.3638117  -1.1188521  -0.41904187\n",
            "    1.2559104  -1.0523725   0.1830308 ]\n",
            "  [-1.4311919  -0.02260348 -1.6890111  -0.07864736  0.83019143\n",
            "    0.5781312   0.4456839   1.3674471 ]\n",
            "  [ 1.6884197  -0.82774734  1.1712735  -0.5982174  -0.5281771\n",
            "   -0.84998554 -0.95803636  0.9024703 ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.print(out[0].numpy().mean(), out[0].numpy().std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDAMfnZP4KTw",
        "outputId": "7173a68a-dfc5-4428-b692-e3384008b48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.9868216e-08 0.99999344\n"
          ]
        }
      ]
    }
  ]
}